# Layer Technique papers

## 1. Batch_Normalization
 * paper link : https://arxiv.org/abs/1502.03167
 * explain link : [https://shuuki4.wordpress.com/2016/01/13/batch-normalization-%EC%84%A4%EB%AA%85-%EB%B0%8F-%EA%B5%AC%ED%98%84/](https://shuuki4.wordpress.com/2016/01/13/batch-normalization-설명-및-구현/)

## 2. optimizer_adam_thesis(23_Jul_2015)
 * link : https://arxiv.org/abs/1412.6980

## 3. practical-bayesian-optimization
 * link : https://arxiv.org/abs/1206.2944

## 4. SVD
 * link : http://lsa.colorado.edu/papers/JASIS.lsi.90.pdf

## 5. variational Dropout
 * link : https://arxiv.org/abs/1701.05369

## 6. Non_maximum_suppresion

* GreedyNMS link : https://arxiv.org/abs/1705.02950

* explain link : https://dyndy.tistory.com/275

* PPT explain : https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&loop=false&delayms=3000&slide=id.g137784ab86_4_1252

## 7. recall & precision

* link : https://darkpgmr.tistory.com/162

## 학습 관련 기술들

* link : [https://ratsgo.github.io/deep%20learning/2017/04/22/NNtricks/](https://ratsgo.github.io/deep learning/2017/04/22/NNtricks/)