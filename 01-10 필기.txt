※ 알고리즘 13번 LRU알고리즘

	LRU	----->     오라클 DB의 메모리를 효율적으로 사용하기 위해 쓴 알고리즘
	 │
	 └──▶ Least Recent Use







■ 앞에서 배운 내용 복습

	1장. 신경망을 구현하기 위해 알아야 하는 파이썬 문ㅂ버 
		- numpy 사용법
		- matplot 그래프 그리는 모듈 사용법

	2장. 퍼셉트론
		"신경망안에 뉴런 1개를 컴퓨터로 구현"

	   * 퍼셉트론의 종류 2가지
		1. 단층 퍼셉트론
		2. 다층 퍼셉트론

		단층 퍼셉트론의 한계를 다층 퍼셉트론으로 해결했는데 그 한계가 무엇이었는가?
		"xor게이트를 단층퍼셉트론으로는 구현이 불가해서 다층 퍼셉트론으로 해결했다."

	3장. 신경망 구현

		퍼셉트론 	-------------------------->          신경망
		   ↓
		and  게이트
		or   게이트
		nand 게이트
		xor  게이트

		결과를 보려면 w를 사람이 직접 정해줘야 했는데 ----> 신경망은 w를 랜덤으로 지정해주기만
								    하면 컴퓨터가 알아서 w를 알아낸다.


	   * 신경망에 들어가는 활성화 함수 
		"신호를 보낼지 안보낼지를 결정하는 함수"
		"신호를 강하게 보낼지 약하게 보낼지 결정하는 함수"

		1. 계단 함수 : 숫자 0과 1을 리턴하는 함수
			그림 3-_-1

		2. 시그모이드 함수 : 숫자 0~1사이의 실수를 리턴하는 함수
			그림 3-_-2

		3. 렐루 함수 : 입력되는 값이 0보다 크면 그 값을 그대로 출력하고 0이하면 0을 리턴하는 함수
			그림 3-_-3



	   * 시그모이드 함수의 유래
		오즈비율 함수     ---->     로짓함수 그래프     ----->     시그모이드 함수

		     ↓ 			  ↓				  ↓

		실패할 확률 대비	  오즈비율 함수에 로그를	 로짓함수를 신경망에서 p(확률)
		성공할 확률을 구하는	  사용한 함수			 값을 계산하기 편하도록 지수
		함수				      p			 형태로 바꾼 함수
		       p			log(-----)			     1
		     -----			     1-p		        -----------
		     (1-p)							1 + exp(-x)



문제 44. 파이썬으로 계단함수를 만드시오 !

	"숫자 0과 1을 리턴하는 함수"
	 x <= 0 -----> 0을 출력
	 x >  0 -----> 1을 출력

	예시 : x_data = np.array([-1,0,1])
	       print( step_func(x_data))

	import numpy as np
	x_data = np.array([-1,0,1])

	def step_data(data):
	    result = []
	    for i in data:
	        if i <= 0:
	            result.append(0)
	        else:
	            result.append(1)
	    return np.array(result)

	print(step_data(x_data))
	
	[0 0 1]




문제 45. 계단함수를 파이썬으로 시각화 하시오 !

	import numpy as np
	import matplotlib.pyplot as plt
	
	x = np.arange(-5,5,0.01)
	def step_func(data):
	    result = []
	    for i in data:
	        if i <= 0:
	            result.append(0)
	        else:
	            result.append(1)
	    return np.array(result)
	
	y = step_func(x)
	plt.plot(x,y)
	plt.ylim(-0.1, 1.1)
	plt.show()

	그림 3-_-4



문제 46. 시그모이드 함수를 파이썬으로 구현하시오 !

	 * 시그모이드 함수 식 : h(x) = 1 / (1 + np.exp(-x) )

	import numpy as np
	x = np.array([1.0, 2.0])
	
	def sigmoid(data):
	    return 1/( 1 + np.exp(-data) )
	
	print( sigmoid(x))

	[ 0.73105858  0.88079708]




문제 47. 시그모이드 함수의 그래프를 그리시오 !

	import numpy as np
	import matplotlib.pyplot as plt

	x = np.arange(-5,5,0.1)
	
	def sigmoid(data):
	    return 1/( 1 + np.exp(-data) )
	
	y = sigmoid(x)
	plt.plot(x,y)
	plt.show()

	그림 3-_-5








★ Relu 함수 ( Rectified Linear Unit )
		 정류된

	Relu는 입력이 0을 넘으면 그 입력을 그대로 출력하고 0 이하면 0을 출력하는 함수

	신경망 학습이 잘되어서 현업에서 주로 사용하는 함수 



문제 48. Relu 함수를 생성하시오 !

	import numpy as np

	x = np.array([-2, 0.3])
	def relu(data):
	    result = []
	    for i in data:
	        if i <= 0:
	            result.append(0)
	        else:
	            result.append(i)
	    return np.array(result)
	
	print(relu(x))

	[ 0.   0.3]

	선생님 답

	import numpy as np

	x = np.array([-2, 0.3])
	def relu(x):
	    return np.maximum(0,x)
	
	print(relu(x))

	[ 0.   0.3]



문제 49. (점심시간 문제) Relu 함수의 그래프로 그리시오 !

	import numpy as np
	import matplotlib.pyplot as plt
	
	x = np.arange(-5,5, 0.1)
	def relu(data):
	    result = []
	    for i in data:
	        if i <= 0:
	            result.append(0)
	        else:
	            result.append(i)
	    return np.array(result)
	
	y = relu(x)
	plt.plot(x,y)
	plt.show()

	그림 3-_-6










■ 다차원 배열의 계산 (p77)

	넘파이로 행렬을 만들고 차원수 확인과 몇행 몇열인지 확인하는 방법

	예 : 아래의 3행 2열의 행렬을 만드시오 !

		1 2
		3 4
		5 6

		import numpy as np
		b = np.array( [[1, 2], [3, 4], [5, 6]] )
		print(b)
		
		print( np.ndim(b))
		print( b.shape)

		그림 3-_-7






■ 행렬의 내적

	그림 3-_-8



문제 50. 그림 3-_-8 두개의 행렬의 내적을 numpy로 구현하시오 !

	import numpy as np	
	
	a = np.array( [[1, 2], [3, 4]] )
	b = np.array( [[5, 6], [7, 8]] )
	
	print( np.dot(a,b) )
	
	[[19 22]
	 [43 50]]

	또는 np.matrix로 구현한다면 ?
	
	import numpy as np
	
	a = np.matrix( [[1, 2], [3, 4]] )
	b = np.matrix( [[5, 6], [7, 8]] )
	
	print( a*b )


		※ array 와 matrix의 차이는 
			1. array는 다차원을 나타낼수 있는데 matrix는 2차원 밖에 안된다.
			2. array 는 matrix를 포함하고 있기 때문에 matrix는 array가 쓰는 모든 함수를 사용할
			   수 있다.
			3. matrix는 array와 달리 연산의 notation이 더 간단해 진다.



문제 51. 아래의 2차원 행렬을 만드시오 !

	import numpy as np
	
	a = np.array( [[1, 2], [3, 4]] )
	
	print(a.ndim)
	
	2



문제 52. 3차원 행렬을 만들어 보시오 !

	import numpy as np
	
	a = np.array( [[[1, 2], [3, 4]], [[5, 6], [7, 8]]] )
	
	print(a.ndim)
	
	3



문제 53. 4차원 행렬을 만들어 보시오 !

	import numpy as np
	
	a = np.array( [[[[1,2],[3,4]],[[5,6],[7,8]]],[[[9,10],[11,12]],[[13,14],[15,16]]]] )
	print(a)
	print(a.ndim)



문제 54. 아래의 3차원 행렬에서 숫자 5를 출력하시오 !

	import numpy as np
	
	a = np.array( [[[1, 2], [3, 4]], [[5, 6], [7, 8]]] )
	
	print(a[1][0][0])

	5



문제 55. 아래의 4차원 배열에서 숫자 5를 출력하시오 !

	import numpy as np	
	
	a = np.array( [[[[1,2],[3,4]],[[5,6],[7,8]]],[[[9,10],[11,12]],[[13,14],[15,16]]]] )
	
	print(a[0][1][0][0])

	5



문제 56. 아래의 행렬의 내적을 파이썬으로 구현하시오 !

		1 2 3	     5 6
			⊙   7 8
		4 5 6        9 10


	import numpy as np
	
	a = np.array( [[1, 2, 3], [4, 5, 6]] )
	b = np.array( [[5, 6], [7, 8], [9, 10]] )
	print(np.dot(a,b))

	







★ 신경망 내적 (p82)

	그림 3-_-9



문제 57. 위의 신경망과 연관된 아래의 방정식에서 x1과 x2가 1과 2이면 y1과 y2와 y3의 값은 무엇인가?
	 파이썬의 numpy로 y1, y2, y3 을 출력하시오 !

	import numpy as np 
	
	x = np.array([1, 2])
	w = np.array([[1, 2], [3 ,4], [5, 6]])
	print(x)
	print(w.T)
	print(np.dot(x,w.T))



문제 58. 아래의 단층 신경망의 출력값 y1 과 y2를 출력하시오 !

	import numpy as np 
	
	x = np.array([4, 5, 7, 2])
	w = np.array([[8, 4, 6, 12], [21, 5, 34, 2], [1, 9, 4, 5]])
	
	print(np.dot(x,w.T))
	
	[118 351  87]




문제 59. 문제 57번 신경망에 가중의 총합인 y값을 시그모이드 함수에 통과시켜서 나온 y_hat을 출력하시오 !

	import numpy as np 
	
	x = np.array([1, 2])
	w = np.array([[1, 2], [3 ,4], [5, 6]])
	
	def sigmoid(data):
	    return 1/( 1 + np.exp(-data) )
	
	y = np.dot(x,w.T)
	y_hat = sigmoid(y)
	print(y_hat)

	[ 0.99330715  0.9999833   0.99999996]




문제 60. 아래의 3층 신경망을 구현하고 j1과 j2를 출력하시오 ! (3층 신경망)

	그림 3-_-10

	import numpy as np 
	
	x = np.array([1, 2])
	w1 = np.array([[1, 2], [3 ,4], [5, 6]])
	w2 = np.array([[3, 5, 7], [4, 6, 8]])
	w3 = np.array([[4, 6], [5, 7]])
	
	def sigmoid(data):
	    return 1/( 1 + np.exp(-data) )
	
	y = np.dot(x,w1.T)
	y_hat = sigmoid(y)
	z = np.dot(y_hat,w2.T)
	z_hat = sigmoid(z)
	j = np.dot(z_hat, w3.T)
	print(j)

	[  9.99999866  11.99999833]







★ 출력층 함수 (p90)

	"출력층의 함수는 그동안 흘러왔던 확률들의 숫자를 취합해서 결론을 내줘야 하는 함수 !"

	신경망으로 구현하고자 하는 문제가

		1. 회귀면 ? 항등함수
			예 : 독립변수 ( 콘크리트 재료 : 자갈 200kg, 시멘트 20포대....)
			     종속변수 ( 콘크리트 강도 )

		2. 분류면 ? 소프트 맥스 함수
			예 : 정상 폐사진  vs  폐결절 사진



문제 61. 입력값을 받아 그대로 출력하는 항등함수를 identify_function이라는 이름으로 생성하시오 !

	x = np.array([[1, 2]])
	
	def identify_func(x):
	    return x
	
	print(identify_func(x))
	
	[[1 2]]



문제 62. 문제 60번에서 만든 3층 신경망의 3층 출력층에 항등함수를 달아서 j1_hat과 j2_hat을 구하는 코드로 
	 완성시키시오 !

	import numpy as np 
	
	def sigmoid(data):
	    return 1/( 1 + np.exp(-data) )
	
	def identify_func(x):
	    return x

	# 0층 (입력층)
	x = np.array([1, 2])

	# 1층 (은닉 1층)
	w1 = np.array([[1, 2], [3 ,4], [5, 6]])   # 1층의 가중치
	y = np.dot(x,w1.T)
	y_hat = sigmoid(y)

	# 2층 (은닉 2층)
	w2 = np.array([[3, 5, 7], [4, 6, 8]])   # 2층의 가중치
	z = np.dot(y_hat,w2.T)
	z_hat = sigmoid(z)

	# 출력층
	w3 = np.array([[4, 6], [5, 7]])   # 3층의 가중치
	j = np.dot(z_hat, w3.T)
	j_hat = identify_func(j)
	print(j_hat)
	
	[  9.99999866  11.99999833]



문제 63. 위의 3층 신경망에 활성화 함수를 relu 함수로 변경하시오 !

	import numpy as np 
	
	def sigmoid(data):
	    return 1/( 1 + np.exp(-data) )
	
	def identify_func(x):
	    return x
	
	def relu(x):
	    return np.maximum(0,x)
	
	# 0층 (입력층)
	x = np.array([1, 2])
	
	# 1층 (은닉 1층)
	w1 = np.array([[1, 2], [3 ,4], [5, 6]])   # 1층의 가중치
	y = np.dot(x,w1.T)
	y_hat = relu(y)
	
	# 2층 (은닉 2층)
	w2 = np.array([[3, 5, 7], [4, 6, 8]])   # 2층의 가중치
	z = np.dot(y_hat,w2.T)
	z_hat = relu(z)
	
	# 출력층
	w3 = np.array([[4, 6], [5, 7]])   # 3층의 가중치
	j = np.dot(z_hat, w3.T)
	j_hat = identify_func(j)
	print(j_hat)

	[2088 2499]













