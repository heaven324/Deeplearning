★ 신경망의 종류 2가지

	1. 단층 신경망 			선형 분류

		입력층 -------> 출력층
		 0층		  1층

		그림 2-_-6


							  반복
		1957년 로젠블라트 ┬────▶ 뇌 : 신호 -----> 암기
				  │
				  │				   가중치
				  └────▶ 인공신경망 : 신호 ┬────▶ 1 (흐른다)
								 └────▶ 0 (안흐른다)
		그림 2-_-7	



		퍼셉트론 ? 
			사람의 뇌 세포 하나를 단층 신경망으로 구현
			n개의 이진수가 하나의 뉴런을 통과해서 가중의 합이 0보다 크면 활성화 되는 가장
			간단한 신경망




	2. 다층 신경망			비선형 분류

		얕은 신경망 : 입력층 -----> 은닉층 -----> 출력층
			       0층	     1층	   2층

		깊은 신경망 : 입력층 -----> 은닉층들 -----> 출력층
			       0층	       1층	     2층
				(Deep learning)








★ 퍼셉트론 게이트 4가지

	1. And  게이트

		x1	x2	y
		0	0	0
		0	1	0		그림 2-_-1
		1	0	0
		1	1	1


	2. Or   게이트

		x1	x2	y
		0	0	0
		0	1	1		그림 2-_-2
		1	0	1
		1	1	1


	3. NAnd 게이트 (Not And)

		x1	x2	y
		0	0	1
		0	1	1		그림 2-_-3
		1	0	1
		1	1	0


	4. XOr  게이트 (Exclusive Or라는 뜻으로 둘중에 하나만 1이 될 때 1이 된다)

		그림 2-_-4

		x1	x2	y
		0	0	0
		0	1	1		그림 2-_-5
		1	0	1
		1	1	0



그림 2-_-6

	입력신호의 연결강도가 가중치인데 가중치의 값이 클수록 "강한 신호"이다
	
	입력신호가 뉴런에 보내질때는 각각의 고유한 가중치 곱해진다.
	
	w1 * x1 + w2 * x2 <= 임계값(θ) ----> 0 (신호가 안흐른다)
	w1 * x1 + w2 * x2 >  임계값(θ) ----> 0 (신호가 흐른다)
	
	뉴런에서 보내온 신호의 총합이 정해진 한계(임계값)을 넘어설 때만 1을 출력한다.
	
	퍼셉트론은 n개의 이진수가 하나의 뉴런을 통과해서 가중의 합이 0보다 크면 활성화 되는 가장 간단한 
	신경망이다.
	
	퍼셉트론을 학습시키는 방법은 간단한데, 보통 목표치를 정해주고 현재 계산한 값이 목표치와 다르면 그 
	만큼의 오차를 다시 퍼셉트론에 반영해서 오차를 줄여나가는 방법이다.




문제 34. 아래의 식을 파이썬으로 구현하시오 !
	
	그림 2-_-6
	
	x1*w1 + x2*w2 = y
	x1 = 0
	x2 = 1
	w1 = 0.5
	w2 = 0.5
	
	import numpy as np
	
	x = np.array( [0, 1] )
	w = np.array( [0.5, 0.5] )
	print(x*w)
	print(np.sum(x*w))
	
	[ 0.   0.5]
	0.5




문제 35. 위의 식에 책 52쪽에 나오는 편향을 더해서 완성한 아래의 식을 파이썬으로 구현하시오 !

	 b(편향) = -0.7
	 x1 = 0
	 x2 = 1
	 w1 = 0.5
	 w2 = 0.5
	
	import numpy as np
	
	b = np.array( [-0.7] )
	x = np.array( [0, 1] )
	w = np.array( [0.5, 0.5] )
	print(np.sum(x*w)+b)

	[-0.2]



문제 36. and게이트를 파이썬으로 구현하시오 !
         (파이썬 함수를 생성하는데 함수 이름은 AND이다)

	책 49페이지 그림 2-2 AND게이트 진리표
	 (w1 : 0.5, w2 : 0.5, theta : 0.7)
	
	 그림 2-_-7

	import numpy as np
	
	def AND(x1,x2):
	    w1,w2,theta = 0.5, 0.5, 0.7
	    if x1*w1 + x2*w2 > theta:
	        return 1
	    else:
	        return 0
	    
	print(AND(0,0))
	print(AND(0,1))
	print(AND(1,0))
	print(AND(1,1))

	0
	0
	0
	1

문제 37. 위에서 만든 and 퍼셉트론 함수를 이용해서 아래의 inputdata를 이용해서 출력 결과를 for loop문으로
	 한번에 출력하시오 !

	import numpy as np
	inputData = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
	
	def AND(x1,x2):
	    w1,w2,theta = 0.5, 0.5, 0.7
	    if x1*w1 + x2*w2 > theta:
	        return 1
	    else:
	        return 0
	
	for i in inputData:
	    print('%d, %d ===> %d'%(i[0], i[1], AND(i[0],i[1])))

	0, 0 ===> 0
	0, 1 ===> 0
	1, 0 ===> 0
	1, 1 ===> 1



문제 38. 문제 37번 코드를 가지고 좀 수정해서 or 게이트 함수를 생성해서 아래와 같이 출력하시오 !

	import numpy as np
	
	inputData = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
	
	def OR(x1,x2):
	    w1,w2,theta = 0.5, 0.5, 0.3
	    if x1*w1 + x2*w2 > theta:
	        return 1
	    else:
	        return 0
	
	for i in inputData:
	    print('%d, %d ===> %d'%(i[0], i[1], OR(i[0],i[1])))

	0, 0 ===> 0
	0, 1 ===> 1
	1, 0 ===> 1
	1, 1 ===> 1



문제 39. (점심시간 문제) Not And Perceptron함수를 구현하시오 !

	import numpy as np
	
	inputData = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
	
	def NAND(x1,x2):
	    w1,w2,theta = 0.5, 0.5, 0.7
	    if x1*w1 + x2*w2 > theta:
	        return 0
	    else:
	        return 1
	
	for i in inputData:
	    print('%d, %d ===> %d'%(i[0], i[1], NAND(i[0],i[1])))
	
	0, 0 ===> 1
	0, 1 ===> 1
	1, 0 ===> 1
	1, 1 ===> 0





★ 퍼셉트론 함수 4가지
	1. AND  게이트 함수 : 단층
	2. OR   게이트 함수 : 단층
	3. NAND 게이트 함수 (Not AND): 단층
	4. XOR  게이트 함수 (eXclusive OR): 다층



★ 단층 신경망과 다층 신경망의 차이 

	- 1958년 로젠 블래트가 퍼셉트론을 제안을 했다.

	- 1959년 민스키가 기존 퍼셉트론의 문제점을 지적했는데 xor분류를 못한다는 문제점을 지적하고
	  인공지능의 겨울기가 시작되었다.
	  즉, xor 게이트는 단층 신경망으로는 구현이 안되는 것이었다.
	      xor 게이트는 다층 신경망으로 구현해야 하는 것이었다.


	1. XOR 게이트 진리 연산표

	xor	x1	x2	t
		0	1	0
		1	0	1
		0	1	1
		1	1	0


	2. 중간층을 넣어서

		입력층(0층)		    은닉1층(1층)	     출력층(2층)

	xor	x1	x2	|	or 결과		NAND 결과  =	AND결과
	----------------------- | -------------------------------- = ----------
		0	0	|	   0		   1	   =	   0
		0	1	|	   1		   1	   =	   1
		1	0	|	   1		   1	   =	   1
		1	1	|	   1		   0	   =	   0

	그림 2-_-8



문제 40. 위에서 만든 3개의 함수 (OR, NAND, AND)를 이용해서 XOR함수를 생성해서 아래와 같이 결과를 출력하시오 !

	import numpy as np
	inputData = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
	
	def OR(x1,x2):
	    w1,w2,theta = 0.5, 0.5, 0.3
	    if x1*w1 + x2*w2 > theta:
	        return 1
	    else:
	        return 0
	
	def NAND(x1,x2):
	    w1,w2,theta = 0.5, 0.5, 0.7
	    if x1*w1 + x2*w2 > theta:
	        return 0
	    else:
	        return 1
	
	def AND(x1,x2):
	    w1,w2,theta = 0.5, 0.5, 0.7
	    if x1*w1 + x2*w2 > theta:
	        return 1
	    else:
	        return 0
	    
	def XOR(x1,x2):
	    xx1 = OR(x1,x2)
	    xx2 = NAND(x1,x2)
	    return AND(xx1, xx2)
		    
	for i in inputData:
	    print('%d, %d ===> %d'%(i[0], i[1], XOR(i[0],i[1])))

	0, 0 ===> 0
	0, 1 ===> 1
	1, 0 ===> 1
	1, 1 ===> 0




문제 41. 2장에서 배운 퍼셉트론의 4개의 게이트함수를 이용해서 아래의 결과를 출력하시오 !

	import numpy as np
	inputData = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
	
	def OR(x1,x2):
	    w1,w2,theta = 0.5, 0.5, 0.3
	    if x1*w1 + x2*w2 > theta:
	        return 1
	    else:
	        return 0
	
	def NAND(x1,x2):
	    w1,w2,theta = 0.5, 0.5, 0.7
	    if x1*w1 + x2*w2 > theta:
	        return 0
	    else:
	        return 1
	
	def AND(x1,x2):
	    w1,w2,theta = 0.5, 0.5, 0.7
	    if x1*w1 + x2*w2 > theta:
	        return 1
	    else:
	        return 0
	    
	def XOR(x1,x2):
	    xx1 = OR(x1,x2)
	    xx2 = NAND(x1,x2)
	    return AND(xx1, xx2)
	
	print('---- And 퍼셉트론 ----')
	for i in inputData:
	    print('%d, %d ===> %d'%(i[0], i[1], AND(i[0],i[1])))
	    
	print('---- Or 퍼셉트론 ----')
	for i in inputData:
	    print('%d, %d ===> %d'%(i[0], i[1], OR(i[0],i[1])))
	
	print('---- Nand 퍼셉트론 ----')
	for i in inputData:
	    print('%d, %d ===> %d'%(i[0], i[1], NAND(i[0],i[1])))
	    
	print('---- Xor 퍼셉트론 ----')
	for i in inputData:
	    print('%d, %d ===> %d'%(i[0], i[1], XOR(i[0],i[1])))

	---- And 퍼셉트론 ----
	0, 0 ===> 0
	0, 1 ===> 0
	1, 0 ===> 0
	1, 1 ===> 1
	---- Or 퍼셉트론 ----
	0, 0 ===> 0
	0, 1 ===> 1
	1, 0 ===> 1
	1, 1 ===> 1
	---- Nand 퍼셉트론 ----
	0, 0 ===> 1
	0, 1 ===> 1
	1, 0 ===> 1
	1, 1 ===> 0
	---- Xor 퍼셉트론 ----
	0, 0 ===> 0
	0, 1 ===> 1
	1, 0 ===> 1
	1, 1 ===> 0







문제 42. 2장 총정리 62페이지에 나오는 글 맨 마지막에 "다층 퍼셉트론을 컴퓨터로 구현할 수 있다"는 것을 
	 파이썬 코드로 구현하시오 !

	1. 어제 구현한 단층 함수인 AND 퍼셉트론 함수로 AND에 해당하는 w0, w1, w2만 변경을 했는데

	2. 다층은 AND, NAND, OR 3개의 함수의 각각의 w0, w1, w2를 갱신해야 한다.


	결과 :
	  
	NAND의 w : [-0.1  -0.05 -0.05] 
	OR의   w : [ 0.15  0.45  0.25] 
	AND의  w : [ 0.2  -0.05  0.25]


	import numpy as np
	x = np.array( [ [-1, 0, 0], [-1, 0, 1], [-1, 1, 0], [-1, 1, 1] ] )
	xx = np.array( [ [-1, 0, 1], [-1, 1, 1], [-1, 1, 1], [-1, 1, 0] ] )
	w = np.array ( [0.4, 0.35, 0.05] )
	
	or_targets = np.array( [[0], [1], [1], [1]] )
	nand_targets = np.array( [[1], [1], [1], [0]] )
	and_targets = np.array( [[0], [1], [1], [0]] )
	
	def active_func(k):
	    if k > 0:
	        return 1
	    elif k <= 0:
	        return 0
	    
	def logi_sum(x,w, targets):
	    while True:
	        w1 = []
	        k_list = np.sum(x*w, axis=1)
	        for i in range(len(k_list)):
	            k = active_func(k_list[i])
	            if (targets[i][0] - k) != 0:
	                w1 = []
	                for j in range(len(w)):
	                    w1.append(w[j] + 0.05*x[i][j]*(targets[i][0] - k))
	                break
	        if w1 == []:
	            break
	        w = np.array(w1)
	    return w
	
	print('OR  의 w :',logi_sum(x,w,or_targets))
	print('NAND의 w :',logi_sum(x,w,nand_targets))
	print('AND 의 w :',logi_sum(xx,w,and_targets))

	OR  의 w : [ 0.2   0.35  0.25]
	NAND의 w : [-0.15 -0.1  -0.05]
	AND 의 w : [ 0.4   0.35  0.1 ]




■ 3장. 신경망

	* 퍼셉트론과 신경망의 차이점 ?

	    1. 퍼셉트론 ?
		

	편향 ? 
	뉴런이 얼마나 쉽게 활성화 되는지를 제어한다.
	편향이 없다면 모든 뉴련이 원점을 통과하는 결과가 발생.



★ 활성화 함수 ? 

	입력신호의 총합을 출력신호로 변환하는 함수

	그림 2-_-9



★ 활성화 함수의 종류 3가지

	1. Step함수
		극명하게 두가지 케이스로 나뉘어 주는 함수
		극명하게 둘로 나뉜다면 애매한 내용들을 표현하기가 어렵다
		그림 2-_-10
		그림 2-_-13


	2. Sigmoid 함수
		step함수를 보완해 애매한 내용들을 0~1사이의 실수로 표현하는 함수
		그림 2-_-11
		그림 2-_-14

	3. Relu 함수	(현업에서 가장 많이 사용)
		입력이 0을 넘으면 그 입력을 그대로 출력		표현을 강하게 약하게 할 수 있다.
		입력이 0이하면 0을 출력				아닌건 모두 0으로
		그림 2-_-12
		그림 2-_-15




★ 시그모이드 함수의 유래

	통계학에서는 성공확률이 실패확률보다 얼마나 클지를 나타내는 오즈비율이라는 값이 있다.

	Odds = 성공/실패 = p/(1-p)
	그림 2-_-16

	이 그래프는 p의 값이 1에 가까우면 오즈값이 급격히 커져버리는 현상이 일어나 p/(1-p)에 로그를 취한게
	로짓함수 이다 log(p/(1-p))
	그림 2-_-17















